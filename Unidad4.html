<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <title>Unidad 4</title>
  <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico">
  <!-- Font Awesome icons (free version)-->
  <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
  <!-- Google fonts-->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css">
  <!-- Core theme CSS (includes Bootstrap)-->
  <link href="css/styles.css" rel="stylesheet">
</head>

<body id="page-top" bgcolor="#00FF00">
  <center>
  <!-- Navigation-->
  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
    </a>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
    </div>
  </nav>
  <!-- Page Content-->
  <div class="container-fluid p-0">
    <!-- About-->
    <hr class="m-0">
    <!-- Experience-->
    <hr class="m-0">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <div class="row">
            <div class="col-md-5" style="">
              <h1 class="m-0 ml-5 mr-4 mb-2" style= "color: -rgb(255, 0, 0);">Unidad 4</h1>
            </div>
            <div class="col-md-6" style="">
              <h2 class="mt-3" style= "color: -rgb(255, 0, 0);">PROCESAMIENTO PARALELO</h2>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <!-- Bootstrap core JS-->
  <div class="py-5" style="">
    <div class="container">
      <div class="row">
        <div class="col-md-12"></div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
      </div>
      <div class="row">
        <div class="col-md-12">
          <h3 class="mt-4" style= "color: -rgb(255, 0, 0);">4.1 Aspectos básicos de la computación paralela</h3>
          <p class=""><b>La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia. Como el consumo de energía —y por consiguiente la generación de calor— de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.</b><br><b>Los programas informáticos paralelos son más difíciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los más comunes. La comunicación y sincronización entre diferentes subtareas son algunos de los mayores obstáculos para obtener un buen rendimiento del programa paralelo. La máxima aceleración posible de un programa como resultado de la paralelización se conoce como la ley de Amdahl.</b></p>
        </div>
      </div>
      <div class="row">
        <div class="col-md-6"><img class="img-fluid d-block mx-auto" src="http://4.bp.blogspot.com/-e-T8dhaYBj0/VHiDT7vYpLI/AAAAAAAAAII/hmA5NeegmW4/s1600/1.jpg"></div>
      </div>
    </div>
  </div>
  <div class="py-5" style="">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h3 class="" style= "color: -rgb(255, 0, 0);">4.2 Tipos de compútación paralela</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class="" style=""><b>PARALELISMO A NIVEL DE BIT:&nbsp;Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo. El aumento del tamaño de la palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra.&nbsp;&nbsp;<br></b><br><b>PARALELISMO A NIVEL DE INSTRUCCIÓN:&nbsp;&nbsp;Los procesadores modernos tienen ”pipeline” de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipeline de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. El ejemplo canónico de un procesador segmentado es un procesador RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4tenía un pipeline de 35 etapas.</b><br><br><b>PARALELISMO DE DATOS:&nbsp;El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. La paralelización de ciclos conduce a menudo a secuencias similares de operaciones (no necesariamente idénticas) o funciones que se realizan en los elementos de una gran estructura de datos. Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.</b><br><br><b>PARALELISMO DE TAREAS:&nbsp;El paralelismo de tareas es la característica de un programa paralelo en la que cálculos completamente diferentes se pueden realizar en cualquier conjunto igual o diferente de datos. Esto contrasta con el paralelismo de datos, donde se realiza el mismo cálculo en distintos o mismos grupos de datos. El paralelismo de tareas por lo general no escala con el tamaño de un problema.</b></p>
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.2.1 Clasificación</h4>
          <p class=""><b>La clasificación de Flynn ha demostrado funcionar bastante bien para la tipificación de sistemas, y se ha venido usando desde décadas por la mayoría de los arquitectos de computadores. Sin embargo, los avances en tecnología y diferentes topologías, han llevado a sistemas que no son tan fáciles de clasificar dentro de los 4 tipos de Flynn. Por ejemplo, los procesadores vectoriales no encajan adecuadamente en esta clasificación, ni tampoco las arquitecturas hibridas. Para solucionar esto se han propuesto otras clasificaciones, donde los tipos SIMD y MIMD de Flynn se suelen conservar, pero que sin duda no han tenido el éxito de la de Flynn.</b><br><b>En 1966 Flynn propuso una clasificación generalista de las computadoras adoptando como criterio el flujo de instrucciones y el flujo de datos que en ellos se desarrolla. La clasificación de Flynn es la siguiente:&nbsp;</b><br><b>SISD: Instrucción única, datos únicos. Las instrucciones se ejecutan secuencialmente pero pueden estar solapadas en las etapas de ejecución.</b></p><img class="img-fluid d-block mx-auto" src="http://3.bp.blogspot.com/-sKJ4jCEa5VQ/VXppPxosbfI/AAAAAAAAANI/qfh0BXPqozE/s1600/sisd.gif">
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class="my-4"><b>SIMD: Instrucción única, datos múltiples. Son los procesadores matriciales en los que existen varias unidades de procesamiento trabajando sobre flujos de datos distintos pero ejecutando la misma instrucción.</b></p><img class="img-fluid d-block mx-auto" src="https://media.geeksforgeeks.org/wp-content/uploads/simd.png">
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class="my-4"><b>MISD: Instrucción múltiple, datos únicos. Este se caracteriza por la existencia de varias unidades de procesamiento cada una ejecutando una instrucción diferente pero sobre el mismo flujo de datos.</b></p>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12"><img class="img-fluid d-block mx-auto" src="https://media.geeksforgeeks.org/wp-content/uploads/misd.png"></div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class="my-4"><b>MIMD: es una técnica empleada para lograr paralelismo. Las máquinas que usan MIMD tienen un número de procesadores que funcionan de manera asíncrona e independiente.</b></p>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12"><img class="img-fluid d-block mx-auto" src="https://media.geeksforgeeks.org/wp-content/uploads/mimd.png"></div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.2.2 Arquitectura de computadoras secuenciales</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class=""><b>Se basa en el número de instrucciones y de la secuencia de datos que la computadora utiliza para procesar información. Puede haber secuencias de instrucciones sencillas o múltiples y secuencias de datos sencillas o múltiples.</b><br><b>A diferencia de los sistemas combinacionales, en los sistemas secuenciales, los valores de las salidas, en un momento dado, no dependen exclusivamente de los valores de las entradas en dicho momento, sino también de los valores anteriores. El sistema secuencial más simple es el biestable.&nbsp;</b><br><b>La mayoría de los sistemas secuenciales están gobernados por señales de reloj. A éstos se los denomina "síncronos" o "sincrónicos", a diferencia de los "asíncronos" o "asincrónicos" que son aquellos que no son controlados por señales de reloj.&nbsp;</b><br><b>A continuación se indican los principales sistemas secuenciales que pueden encontrarse en forma de circuito integrado o como estructuras en sistemas programados:&nbsp;</b><br><b>* Contador&nbsp;</b><br><b>* Registros&nbsp;</b><br><b>En todo sistema secuencial nos encontraremos con:&nbsp;<br>a) Un conjunto finito, n, de variables de entrada (X1, X2,..., Xn).&nbsp;</b><br><b>b) Un conjunto finito, m, de estados internos, de aquí que los estados secuenciales también sean denominados autómatas finitos. Estos estados proporcionarán m variables internas (Y1,Y2,..., Ym).&nbsp;</b><br><b>c) Un conjunto finito, p, de funciones de salida (Z1, Z2,..., Zp).</b></p>
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.2.3 Organización de direcciones de memoria</h4>
          <p class=""><b>Los métodos más comunes de implementación son mediante:&nbsp;</b><br><b>* Técnicas de “paginación”.&nbsp;</b><br><b>* Técnicas de “segmentación”.&nbsp;</b><br><b>* Una combinación de ambas técnicas.&nbsp;</b><br><b>Las direcciones generadas por los programas en su ejecución no son, necesariamente, aquellas contenidas en el almacenamiento primario (memoria real), ya que las direcciones virtuales suelen seleccionarse dentro de un número mucho mayor de direcciones que las disponibles dentro del almacenamiento primario.</b><br><br><br><b>La evolución en las organizaciones de almacenamiento puede resumirse como sigue:&nbsp;</b><br><b>+ Real: Sistemas dedicados a un solo usuario.&nbsp;</b><br><b>+ Real: Sistemas de multiprogramación en memoria real:&nbsp;</b><br><b>- Multiprogramación en partición fija:&nbsp;</b><br><b>* Absoluta.&nbsp;</b><br><b>* Relocalizable (reubicable).&nbsp;</b><br><b>- Multiprogramación en partición variable.&nbsp;</b><br><b>+ Virtual:&nbsp;</b><b>Multiprogramación en almacenamiento virtual:&nbsp;</b><br><b>- Paginación pura.&nbsp;</b><br><b>- Segmentación pura.&nbsp;</b><br><b>- Combinación paginación / segmentación.</b></p>
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h3 class="" style= "color: -rgb(255, 0, 0);">4.3 Sistemas de memoria (compartida)&nbsp;<br>multiprocesadores<br></h3>
          <p class=""><b>Un multiprocesador puede verse como un computador paralelo compuesto por varios procesadores interconectados que comparten un mismo sistema de memoria.&nbsp;<br>Los sistemas multiprocesadores son arquitecturas MIMD con memoria compartida. Tienen un único espacio de direcciones para todos los procesadores y los mecanismos de comunicación se basan en el paso de mensajes desde el punto de vista del programador.&nbsp;<br>Dado que los multiprocesadores comparten diferentes módulos de memoria, pudiendo acceder a un mismo módulo varios procesadores, a los multiprocesadores también se les llama sistemas de memoria compartida.</b><br><b>Dependiendo de la forma en que los procesadores comparten la memoria, se clasifican en sistemas multiprocesador UMA, NUMA y COMA.</b><br><b>Multiproceso es tradicionalmente conocido como el uso de múltiples procesos concurrentes en un sistema en lugar de un único proceso en un instante determinado. Como la multitarea que permite a múltiples procesos compartir una única CPU, múltiples CPUs pueden ser utilizados para ejecutar múltiples hilos dentro de un único proceso.&nbsp;</b><br><b>El multiproceso para tareas generales es, a menudo, bastante difícil de conseguir debido a que puede haber varios programas manejando datos internos (conocido como estado o contexto) a la vez.&nbsp;</b><br><b>Los programas típicamente se escriben asumiendo que sus datos son incorruptibles. Sin embargo, si otra copia del programa se ejecuta en otro procesador, las dos copias pueden interferir entre sí intentando ambas leer o escribir su estado al mismo tiempo.&nbsp;</b><br><b>Para evitar este problema se usa una variedad de técnicas de programación incluyendo semáforos y otras comprobaciones y bloqueos que permiten a una sola copia del programa cambiar de forma exclusiva ciertos valores.</b></p><img class="img-fluid d-block mx-auto" src="https://sites.google.com/site/sistemasoperativospaty/_/rsrc/1338235136491/unidad-4/41-configuraciones-memoria-compartida-distribuida/Configuracion%20de%20mem%20comp.jpg">
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.3.1 Redes de interconexión dinámica (indirecta).&nbsp;<br>Medio compartido.&nbsp;<br>Conmutadas</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class=""><b>Las redes dinámicas se utilizan sobre todo en los multiprocesadores. En este caso, la red une los procesadores a los bancos de memoria central. Cualquier acceso de un procesador a la memoria (bien sea para acceder a los datos o a las instrucciones) debe pasar a través de la red, por lo se dice que la red tiene un acoplamiento fuerte. La red debe poseer un rendimiento extremadamente bueno para no demorar demasiado a los procesadores que acceden a memoria.</b><br><b>Una red dinámica es una red cuya topología puede variar durante el curso de la ejecución de un programa paralelo o entre dos ejecuciones de programas. La red está constituida por elementos materiales específicos, llamados commutadores o switches.&nbsp;</b><br><b>En el mundo de las comunicaciones, y de las redes de computadores en particular, el medio que se utiliza para comunicarse suele estar compartido.</b><br><b>En el caso de la televisión o la radio, existen diferentes canales y emisoras que están compartiendo el medio. A fin de que no haya problemas, hay una regulación del espectro radioeléctrico: se tiene cuidado de que cada uno de los canales tenga asignada una frecuencia determinada y que no haya más de un canal usando la misma frecuencia. Este sistema se llama multiplexación por división de frecuencia y no sólo se utiliza en la radio y la televisión.</b><br><b>&nbsp;Cuando se va a enviar datos a largas distancias (e incluso a no tan largas), este debe pasar por varios nodos intermedios. Los cuáles son los encargados de dirigir los datos para que lleguen a su destino. Por lo cual se hace uso de lo que es una red conmutada. ya que estas Consisten en un conjunto de nodos interconectados entre sí, a través de medios de transmisión , formando así la mayoría de las veces una topología mallada, donde la información se traslada encaminándola del nodo de origen al nodo destino mediante conmutación entre nodos intermedios.</b><br><b>En pocas palabras se puede decir que una red conmutada es aquella que permite la comunicación de nodo a nodo a través de su conexión, para facilitar el traslado de información.<br></b></p><img class="img-fluid d-block mx-auto" src="https://www.sites.google.com/site/comdatosgrupo4/_/rsrc/1271886456741/contenidos/cap4_conmutacion-enrutamiento/a.JPG">
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h3 class="" style= "color: -rgb(255, 0, 0);">4.4 Sistemas de memoria distribuida</h3>
          <p class=""><b>Consta de un único computador con múltiples CPUs comunicadas por un bus de datos mientras que en el segundo se utilizan múltiples computadores, cada uno con su propio procesador, enlazados por una red de interconexión más o menos rápida.&nbsp;<br>Sobre los sistemas de multicomputadores de memoria distribuida, se simula memorias compartidas. Se usan los mecanismos de comunicación y sincronización de sistemas multiprocesadores.&nbsp;</b><br><b>Un clúster es un tipo de arquitectura paralela distribuida que consiste de un conjunto de computadores independientes interconectados operando de forma conjunta como único recurso computacional sin embargo, cada computador puede utilizarse de forma independiente o separada.</b><br><b>En esta arquitectura, el computador paralelo es esencialmente una colección de procesadores secuenciales, cada uno con su propia memoria local, que pueden trabajar conjuntamente.&nbsp;</b><br><b>1) Cada nodo tiene rápido acceso a su propia memoria y acceso a la memoria de otros nodos mediante una red de comunicaciones, habitualmente una red de comunicaciones de alta velocidad.&nbsp;</b><br><b>2) Los datos son intercambiados entre los nodos como mensajes a través de la red.&nbsp;</b><br><b>3) Una red de ordenadores, especialmente si disponen de una interconexión de alta velocidad, puede ser vista como un multicomputador de memoria distribuida y como tal ser utilizada para resolver problemas mediante computación paralela.</b></p><img class="img-fluid d-block mx-auto" src="https://www.researchgate.net/profile/Federico-Meza/publication/238749790/figure/fig1/AS:669372611829765@1536602275309/Figura-1-Sistema-de-Memoria-Compartida-Distribuida.png" width="300" height="300">
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.4.1 Redes de interconexión estáticas</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class=""><b>Las redes estáticas emplean enlaces directos fijos entre los nodos. Estos enlaces, una vez fabricado el sistema son difíciles de cambiar, por lo que la escalabilidad de estas topologías es baja. Las redes estáticas pueden utilizarse con eficiencia en los sistemas en que pueden predecirse el tipo de tráfico de comunicaciones entre sus procesadores.&nbsp;</b><br><b>Clases de redes de interconexión:&nbsp;</b><br></p>
          <ul class="list-group list-group-flush">
            <li class="list-group-item"><b>Formación lineal: Se trata de una red unidimensional en que los nodos se conectan cada uno con el siguiente medianteN-1 enlaces formando una línea. </b></li>
            <li class="list-group-item"><b> Mallas y toros: Esta red de interconexión es muy utilizada en la práctica. Las redes en toro son mallas en que sus filas y columnas tienen conexiones en anillo, esto contribuye a disminuir su diámetro. Esta pequeña modificación permite convertir a las mallas en estructuras simétricas y además reduce su diámetro a la mitad.</b></li>
          </ul>
        </div>
      </div>
    </div>
  </div>
  <div class="py-5">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h4 class="" style= "color: -rgb(255, 0, 0);">4.5 Casos para estudio</h4>
        </div>
      </div>
      <div class="row">
        <div class="col-md-12">
          <p class="mb-4"><b>Por numerosos motivos, el procesamiento distribuido se ha convertido en un área de gran importancia e interés dentro de la Ciencia de la Computación, produciendo profundas transformaciones en las líneas de I/D.&nbsp;</b><br><b>Interesa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas.&nbsp;</b><br><b>Interesa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas</b></p>
          <h5 class="mt-3" contenteditable="true">Líneas De Investigación Y Desarrollo</h5>
          <p class=""><b>- Paralelización de algoritmos secuenciales. Diseño y optimización de algoritmos.&nbsp;</b><br><b>- Arquitecturas multicore y multithreading en multicore.</b><br><b>- Arquitecturas multiprocesador.&nbsp;</b><br><b>- Modelos de representación y predicción de performance de algoritmos paralelos.&nbsp;</b><br><b>- Mapping y scheduling de aplicaciones paralelas sobre distintas arquitecturas multiprocesador.&nbsp;</b><br><b>- Métricas del paralelismo. Speedup, eficiencia, rendimiento, granularidad, superlinealidad.&nbsp;</b><br><b>- Balance de carga estático y dinámico. Técnicas de balanceo de carga.&nbsp;</b><br><b>- Análisis de los problemas de migración y asignación óptima de procesos y datos a procesadores. Migración dinámica.</b><br><b>- Patrones de diseño de algoritmos paralelos.&nbsp;</b><br><b>- Escalabilidad de algoritmos paralelos en arquitecturas multiprocesador distribuidas.&nbsp;</b><br><b>- Implementación de soluciones sobre diferentes modelos de arquitectura homogéneas y heterogéneas (multicores, clusters, multiclusters y grid). Ajuste del modelo de software al modelo de hardware, a fin de optimizar el sistema paralelo.&nbsp;</b><br><b>- Evaluación de performance.&nbsp;</b><br><b>- Laboratorios remotos para el acceso transparente a recursos de cómputo paralelo.&nbsp;</b><br><b>Grandes empresas y sus implementaciones con procesamiento paralelo:&nbsp;&nbsp;</b><br><b>NVIDIA PYSICS LAYER:&nbsp;</b><br><b>* GPU PhysX&nbsp;</b><br><b>* CPU PhysX&nbsp;</b><br><b>Graphics Layer:&nbsp;</b><br><b>* GPU –DirectX Windows&nbsp;</b><br><b>INTEL PYSICS LAYER:&nbsp;</b><br><b>* No GPU PhysX&nbsp;</b><br><b>* CPU Havok&nbsp;</b><br><b>Graphics Layer:&nbsp;</b><br><b>* GPU –Direct X Windows&nbsp;</b><br><b>AMD PYSICS LAYER:&nbsp;</b><br><b>* No GPU PhysX&nbsp;</b><br><b>CPU Havok&nbsp;</b><br><b>* Graphics Layer:&nbsp;</b><br><b>* GPU –DirectX Windows</b></p>
        </div>
      </div>
    </div>
    </div>
    </div>
        </div>
      </div>
    </div>
  </div>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
  <!-- Third party plugin JS-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
  <!-- Core theme JS-->
  <script src="js/scripts.js"></script>
  <style>.footer,.generic-footer{margin-bottom:98px}@media (min-width:374px){.footer,.generic-footer{margin-bottom:78px}}@media (min-width:546px){.footer,.generic-footer{margin-bottom:56px}}@media (min-width:1055px){.footer,.generic-footer{margin-bottom:0}}.disclaimer{position:fixed;z-index:9999999;bottom:0;right:0;border-top:2px solid #ff5c62;text-align:center;font-size:14px;font-weight:400;background-color:#fff;padding:5px 10px 5px 10px}.disclaimer a:hover{text-decoration:underline}@media (min-width:1052px){.disclaimer{text-align:right;border-left:2px solid red;border-top-left-radius:10px}}@media (min-width:1920px){.disclaimer{width:60%}}</style><div class="disclaimer">We support Ukraine and condemn war. Push Russian government to act against war. Be brave, vocal and show your support to Ukraine. Follow the latest news <a title="https://www.bbc.com/news/live/world-europe-60517447" target="_blank" href="https://www.bbc.com/news/live/world-europe-60517447" style="color: black;"><b>HERE</b></a></div></body>
</center>
</html>